{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interior-basics",
   "metadata": {},
   "source": [
    "# Inferring Topics from IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "established-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-ability",
   "metadata": {},
   "source": [
    "## Exploring the Dataset: [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "physical-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './train/pos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-universe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../neuralnets/aclImdb/train/pos/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reviews \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      3\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT, file)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../neuralnets/aclImdb/train/pos/'"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "for file in os.listdir(ROOT):\n",
    "    path = os.path.join(ROOT, file)\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as fin:\n",
    "            reviews.append(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(reviews[i])\n",
    "    print('=' * 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-relative",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "X = vect.fit_transform(reviews)\n",
    "\n",
    "pd.DataFrame(X.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-advantage",
   "metadata": {},
   "source": [
    "## NMF Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 15\n",
    "nmf = NMF(n_components=N_TOPICS)\n",
    "W = nmf.fit_transform(X)  # Document-topic matrix\n",
    "H = nmf.components_       # Topic-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 words per topic\n",
    "\n",
    "words = np.array(vect.get_feature_names())\n",
    "topic_words = pd.DataFrame(np.zeros((N_TOPICS, 10)), index=[f'Topic {i + 1}' for i in range(N_TOPICS)],\n",
    "                           columns=[f'Word {i + 1}' for i in range(10)]).astype(str)\n",
    "for i in range(N_TOPICS):\n",
    "    ix = H[i].argsort()[::-1][:10]\n",
    "    topic_words.iloc[i] = words[ix]\n",
    "\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a topic mapping\n",
    "\n",
    "topic_mapping = {\n",
    "    'Topic 4': 'TV',\n",
    "    'Topic 7': 'War',\n",
    "    'Topic 8': 'Comedy',\n",
    "    'Topic 12': 'Book Adaptation',\n",
    "    'Topic 13': 'Horror',\n",
    "    'Topic 15': 'Martial Arts / Action'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall the document-topic matrix, W\n",
    "\n",
    "W = pd.DataFrame(W, columns=[f'Topic {i + 1}' for i in range(N_TOPICS)])\n",
    "W['max_topic'] = W.apply(lambda x: topic_mapping.get(x.idxmax()), axis=1)\n",
    "W[pd.notnull(W['max_topic'])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frobenius norm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"Frobenius norm and the condition number:\")\n",
    "print(np.linalg.norm([[1,1,1],[3,4,1],[4,1,2]], 'fro'))\n",
    "print(np.linalg.cond([[1,1,1],[3,4,1],[4,1,2]], 'fro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f617f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
