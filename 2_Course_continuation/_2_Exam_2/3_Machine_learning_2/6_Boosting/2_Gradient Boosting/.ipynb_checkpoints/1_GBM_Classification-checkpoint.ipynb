{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "adfbe30e-7ebb-0f88-d917-d9a8f97c638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Collecting scikit-learn<2,>=1.3.2 (from imbalanced-learn->imblearn)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Collecting joblib<2,>=1.1.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.1\n",
      "    Uninstalling scikit-learn-1.3.1:\n",
      "      Successfully uninstalled scikit-learn-1.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, log_loss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Import and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5af03c82-cb84-d943-f82c-fc0a15d46b48"
   },
   "source": [
    "# 1. Exploratory Data Analysis\n",
    "\n",
    "Let us load in the dataset via the trusty Pandas package into a dataframe object which we call **attrition** and have a quick look at the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e035b071-50f8-43ca-9611-fc47272bb05e"
   },
   "outputs": [],
   "source": [
    "attrition = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57e2bf45-5920-af03-50c1-b5bba334eb11"
   },
   "outputs": [],
   "source": [
    "# Looking for NaN\n",
    "attrition.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition.Age.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c5dc2ed-7608-4d84-c4f6-c591a3be7570"
   },
   "source": [
    "### Correlation of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "112cef65-78b8-7790-e705-b173beea6986"
   },
   "source": [
    "#  Feature Engineering & Categorical Encoding\n",
    "\n",
    "Task of Feature engineering and numerically encoding the categorical values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "937385c7-7b7f-f6d0-d974-0527a7118e98"
   },
   "outputs": [],
   "source": [
    "# Empty list to store columns with categorical data\n",
    "categorical = []\n",
    "for col, value in attrition.items():\n",
    "    if value.dtype == 'object':\n",
    "        categorical.append(col)\n",
    "\n",
    "# Store the numerical columns in a list numerical\n",
    "numerical = attrition.columns.difference(categorical)\n",
    "\n",
    "print(\"Categorical columns:\", categorical)\n",
    "print(\"Numerical columns:\", numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5ec5cd49-f8b3-e36b-75dd-ac95fe0373ac"
   },
   "outputs": [],
   "source": [
    "# Store the categorical data in a dataframe called attrition_cat\n",
    "attrition_cat = attrition[categorical]\n",
    "attrition_cat = attrition_cat.drop(['Attrition'], axis=1) # Dropping the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c3c0c95-3725-80dd-0a73-5c840451a438"
   },
   "source": [
    "Applying the **get_dummies** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can you convert categorial or string or object data into Numerical Format ?\n",
    "\n",
    "# Process of converting your cat data into numerical format - Encoding process \n",
    "\n",
    "# Encoding (15 More )\n",
    "\n",
    "# Label Encoding \n",
    "\n",
    "# One Hot Encoding ( OHE)\n",
    "\n",
    "# Cat_A \n",
    "\n",
    "# Male\n",
    "#Female \n",
    "#Male\n",
    "#Female\n",
    "# Prefer_not_to_say\n",
    "# Male \n",
    "\n",
    "# OHE \n",
    "\n",
    "           # Cat_A_Male    #Cat_A_Female   #Cat_A_Prefer_not_to_say\n",
    "#1# Male      1             0                0 \n",
    "#2#Female     0             1                0\n",
    "#3#Male       1             0                0\n",
    "#4#Female     0             1                0\n",
    "#5# Prefer_not_to_say 0     0                1\n",
    "#6# Male \n",
    "\n",
    "\n",
    "\n",
    "# Label Encoding \n",
    "\n",
    "# Cat_A \n",
    "\n",
    "# Male   2       \n",
    "#Female 1\n",
    "#Male 2\n",
    "#Female 1\n",
    "# Prefer_not_to_say 3\n",
    "# Male 2\n",
    "\n",
    "# Target Encoding \n",
    "# Mean Encoding \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter your object datatypes \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
    "le.transform([\"tokyo\", \"tokyo\", \"paris\",\"amsterdam\"])\n",
    "\n",
    "# list(le.classes_)\n",
    "\n",
    "\n",
    "#0 ,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ea5b0d8-1f13-e56b-72cf-bcbe7dd6fad2"
   },
   "outputs": [],
   "source": [
    "attrition_cat = pd.get_dummies(attrition_cat)\n",
    "attrition_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de8b3a57-6aba-eae7-2be3-dbe0ae761d6a"
   },
   "outputs": [],
   "source": [
    "# Store the numerical features to a dataframe attrition_num\n",
    "attrition_num = attrition[numerical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9de23a93-10b6-33b8-eea8-0cf44c6e5e08"
   },
   "source": [
    "let's concat numerical and caterogial dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b90b69ba-f19d-0707-7c2c-183b8d01130f"
   },
   "outputs": [],
   "source": [
    "# Concat the two dataframes together columnwise\n",
    "attrition_final = pd.concat([attrition_num, attrition_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a295568-fab4-b79a-bc0d-be32ad032b3e"
   },
   "source": [
    "**Target variable**\n",
    "\n",
    "The target in this case is given by the column **Attrition** which contains categorical variables therefore requires numerical encoding. We numerically encode it by creating a dictionary with the mapping given as 1 : Yes and 0 : No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfa5e82f-2dd3-1bee-5b2b-367468be7040"
   },
   "outputs": [],
   "source": [
    "# Define a dictionary for the target mapping\n",
    "target_map = {'Yes':1, 'No':0}\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "target = attrition[\"Attrition\"].apply(lambda x: target_map[x])\n",
    "target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5564e6e1-83ed-75de-2540-0d037e31291b"
   },
   "source": [
    "\n",
    "**Splitting Data into Train and Test sets**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c197f8ee-76b0-7137-f001-83f969637521"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test sets as well as for validation and testing\n",
    "train, test, target_train, target_test = train_test_split(attrition_final, target, train_size= 0.75,random_state=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementing Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "610cfa87-0b9d-4671-cd51-c99ef9c9151d"
   },
   "source": [
    "## GBM Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.n_estimators - No of Trees in the Model\n",
    "\n",
    "### 2.max_features - The number of features to consider while searching for a best split.Thumb Rule to have Square root of no of Columns\n",
    "\n",
    "### 3.max_depth - Maximum Depth of Tree and can be used to control overfiting \n",
    "\n",
    "### 4.min_samples_leaf - Minimum samples (or observations) required in a terminal node or leaf.In general we need to have lower values  for it for Imbalanced problems\n",
    "\n",
    "### 5.subsample- The fraction of samples to be used for fitting the individual base learners\n",
    "\n",
    "### 6.learning_rate - Learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=100) # default \n",
    "gb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed6a837e-2864-291c-be8d-3c8e9ed900b7"
   },
   "outputs": [],
   "source": [
    "# Fit the model to our train and target\n",
    "gb.fit(train, target_train)\n",
    "# Get our predictions\n",
    "gb_predictions = gb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_predictions_prob = gb.predict_proba(test)\n",
    "gb_predictions_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Parameters\n",
    "# gb_params ={\n",
    "#     'n_estimators': 500,   # no of Trees \n",
    "#     'learning_rate' : 0.2,\n",
    "#     'max_depth': 11,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'subsample': 1,\n",
    "#     'max_features' : 'sqrt',\n",
    "#     'random_state' : 100,\n",
    "#     'verbose': 0\n",
    "# }\n",
    "\n",
    "#gb = GradientBoostingClassifier(**gb_params) # After Doing HPT , we can pass the paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40c37011-76df-fcc7-9cd0-e689374a8d1a"
   },
   "outputs": [],
   "source": [
    "accuracy_score(target_test, gb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21cc0476-b03e-731f-97b4-89d81977c3a7"
   },
   "source": [
    "### Feature Importance Gradient Boosting Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "082ca641-ffd2-fc3b-a7b6-9418b08767d9"
   },
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "trace = go.Scatter(\n",
    "    y = gb.feature_importances_,\n",
    "    x = attrition_final.columns.values,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        sizemode = 'diameter',\n",
    "        sizeref = 1.3,\n",
    "        size = 12,\n",
    "        color = gb.feature_importances_,\n",
    "        colorscale='Portland',\n",
    "        showscale=True\n",
    "    ),\n",
    "    text = attrition_final.columns.values\n",
    ")\n",
    "data = [trace]\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'GBM Model Feature Importance',\n",
    "    hovermode= 'closest',\n",
    "     xaxis= dict(\n",
    "         ticklen= 5,\n",
    "         showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False\n",
    "     ),\n",
    "    yaxis=dict(\n",
    "        title= 'Feature Importance',\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        ticklen= 5,\n",
    "        gridwidth= 2\n",
    "    ),\n",
    "    showlegend= False\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig,filename='scatter')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 2,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
