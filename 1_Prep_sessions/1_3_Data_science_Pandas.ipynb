{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "\n",
    "1. [Intro_to_dataframes](#Intro_to_dataframes)<br>\n",
    "2. [Operations_on_Pandas](#Operations_on_Pandas)<br>\n",
    "3. [Practice_exercise_1](#Practice_exercise_1)<br>\n",
    "4. [Seoul_dataset](#Seoul_dataset)<br>\n",
    "5. [Sales_dataset](#Sales_dataset)<br>\n",
    "5. [Pandas_Udemy](#Pandas_Udemy)<br>\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color : Brown\"> Data Frame </h2>\n",
    "<a id='Intro_to_dataframes'>Intro_to_dataframes</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style = \"color : Sky blue\"> Example - 1</h4>  \n",
    "\n",
    "##### Create a Data Frame cars using raw data stored in a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_per_cap = [809, 731, 588, 18, 200, 70, 45]\n",
    "country = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "drives_right = [True, False, False, False, True, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"cars_per_cap\": cars_per_cap, \"country\": country, \"drives_right\": drives_right}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cars_per_cap': [809, 731, 588, 18, 200, 70, 45],\n",
       " 'country': ['United States',\n",
       "  'Australia',\n",
       "  'Japan',\n",
       "  'India',\n",
       "  'Russia',\n",
       "  'Morocco',\n",
       "  'Egypt'],\n",
       " 'drives_right': [True, False, False, False, True, True, True]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>country</th>\n",
       "      <th>drives_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>809</td>\n",
       "      <td>United States</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>731</td>\n",
       "      <td>Australia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>588</td>\n",
       "      <td>Japan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>India</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Russia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cars_per_cap        country  drives_right\n",
       "0           809  United States          True\n",
       "1           731      Australia         False\n",
       "2           588          Japan         False\n",
       "3            18          India         False\n",
       "4           200         Russia          True\n",
       "5            70        Morocco          True\n",
       "6            45          Egypt          True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.DataFrame(data)\n",
    "\n",
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style = \"color : Sky blue\"> Example - 2 (Reading data from a file)</h4>  \n",
    "\n",
    "##### Create a Data Frame by importing cars data from cars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USCA</th>\n",
       "      <th>US</th>\n",
       "      <th>United States</th>\n",
       "      <th>809</th>\n",
       "      <th>FALSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LATAM</td>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFR</td>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EUR</td>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USCA   US United States    809  FALSE\n",
       "0  ASPAC  AUS     Australia  731.0   True\n",
       "1  ASPAC  JAP         Japan  588.0   True\n",
       "2  ASPAC   IN         India   18.0   True\n",
       "3  ASPAC   RU        Russia  200.0  False\n",
       "4  LATAM  MOR       Morocco   70.0  False\n",
       "5    AFR   EG         Egypt   45.0  False\n",
       "6    EUR  ENG       England    NaN   True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a file using pandas\n",
    "\n",
    "cars_df = pd.read_csv('./pandas_datasets/cars.csv')\n",
    "\n",
    "cars_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style = \"color : Sky blue\"> Example - 3 (Column headers)</h4>  \n",
    "\n",
    "##### Read file - skip header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USCA</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LATAM</td>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFR</td>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EUR</td>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1              2      3      4\n",
       "0   USCA   US  United States  809.0  False\n",
       "1  ASPAC  AUS      Australia  731.0   True\n",
       "2  ASPAC  JAP          Japan  588.0   True\n",
       "3  ASPAC   IN          India   18.0   True\n",
       "4  ASPAC   RU         Russia  200.0  False\n",
       "5  LATAM  MOR        Morocco   70.0  False\n",
       "6    AFR   EG          Egypt   45.0  False\n",
       "7    EUR  ENG        England    NaN   True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df = pd.read_csv('./pandas_datasets/cars.csv', header=None)\n",
    "\n",
    "cars_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns an array of headers\n",
    "\n",
    "cars_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Headers\n",
    "\n",
    "cars_df.columns = ['country code', 'region', 'country', 'cars_per_cap', 'drive_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country code</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>drive_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USCA</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASPAC</td>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LATAM</td>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AFR</td>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EUR</td>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country code region        country  cars_per_cap  drive_right\n",
       "0         USCA     US  United States         809.0        False\n",
       "1        ASPAC    AUS      Australia         731.0         True\n",
       "2        ASPAC    JAP          Japan         588.0         True\n",
       "3        ASPAC     IN          India          18.0         True\n",
       "4        ASPAC     RU         Russia         200.0        False\n",
       "5        LATAM    MOR        Morocco          70.0        False\n",
       "6          AFR     EG          Egypt          45.0        False\n",
       "7          EUR    ENG        England           NaN         True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style = \"color : Sky blue\"> Example - 4 (Row index/names) </h4>  \n",
    "\n",
    "##### Read file - skip header and assign first column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=8, step=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index is returned by\n",
    "cars_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>drive_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USCA</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATAM</th>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR</th>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region        country  cars_per_cap  drive_right\n",
       "0                                                     \n",
       "USCA      US  United States         809.0        False\n",
       "ASPAC    AUS      Australia         731.0         True\n",
       "ASPAC    JAP          Japan         588.0         True\n",
       "ASPAC     IN          India          18.0         True\n",
       "ASPAC     RU         Russia         200.0        False\n",
       "LATAM    MOR        Morocco          70.0        False\n",
       "AFR       EG          Egypt          45.0        False\n",
       "EUR      ENG        England           NaN         True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file and set 1st column as index\n",
    "cars_df = pd.read_csv(\"./pandas_datasets/cars.csv\", header= None, index_col=0)\n",
    "\n",
    "# set the column names\n",
    "cars_df.columns = ['region', 'country', 'cars_per_cap', 'drive_right']\n",
    "cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USCA', 'ASPAC', 'ASPAC', 'ASPAC', 'ASPAC', 'LATAM', 'AFR', 'EUR'], dtype='object', name=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the new index\n",
    "cars_df.index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rename the Index Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>drive_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USCA</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATAM</th>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR</th>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region        country  cars_per_cap  drive_right\n",
       "country_code                                                 \n",
       "USCA             US  United States         809.0        False\n",
       "ASPAC           AUS      Australia         731.0         True\n",
       "ASPAC           JAP          Japan         588.0         True\n",
       "ASPAC            IN          India          18.0         True\n",
       "ASPAC            RU         Russia         200.0        False\n",
       "LATAM           MOR        Morocco          70.0        False\n",
       "AFR              EG          Egypt          45.0        False\n",
       "EUR             ENG        England           NaN         True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.index.name = 'country_code'\n",
    "cars_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete the index name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>drive_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USCA</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>JAP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>IN</td>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASPAC</th>\n",
       "      <td>RU</td>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATAM</th>\n",
       "      <td>MOR</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR</th>\n",
       "      <td>EG</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>ENG</td>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region        country  cars_per_cap  drive_right\n",
       "USCA      US  United States         809.0        False\n",
       "ASPAC    AUS      Australia         731.0         True\n",
       "ASPAC    JAP          Japan         588.0         True\n",
       "ASPAC     IN          India          18.0         True\n",
       "ASPAC     RU         Russia         200.0        False\n",
       "LATAM    MOR        Morocco          70.0        False\n",
       "AFR       EG          Egypt          45.0        False\n",
       "EUR      ENG        England           NaN         True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.index.name = None\n",
    "cars_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Hierarchical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and set 1st column as index\n",
    "cars_df = pd.read_csv(\"./pandas_datasets/cars.csv\", header= None)\n",
    "\n",
    "# set the column names\n",
    "cars_df.columns = ['country_code','region','country','cars_per_cap','drives_right']\n",
    "\n",
    "cars_df.set_index(['region', 'country_code'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>cars_per_cap</th>\n",
       "      <th>drives_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>country_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <th>USCA</th>\n",
       "      <td>United States</td>\n",
       "      <td>809.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <th>ASPAC</th>\n",
       "      <td>Australia</td>\n",
       "      <td>731.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAP</th>\n",
       "      <th>ASPAC</th>\n",
       "      <td>Japan</td>\n",
       "      <td>588.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <th>ASPAC</th>\n",
       "      <td>India</td>\n",
       "      <td>18.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU</th>\n",
       "      <th>ASPAC</th>\n",
       "      <td>Russia</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOR</th>\n",
       "      <th>LATAM</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EG</th>\n",
       "      <th>AFR</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENG</th>\n",
       "      <th>EUR</th>\n",
       "      <td>England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           country  cars_per_cap  drives_right\n",
       "region country_code                                           \n",
       "US     USCA          United States         809.0         False\n",
       "AUS    ASPAC             Australia         731.0          True\n",
       "JAP    ASPAC                 Japan         588.0          True\n",
       "IN     ASPAC                 India          18.0          True\n",
       "RU     ASPAC                Russia         200.0         False\n",
       "MOR    LATAM               Morocco          70.0         False\n",
       "EG     AFR                   Egypt          45.0         False\n",
       "ENG    EUR                 England           NaN          True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style = \"color : Sky blue\"> Example - 5 (Write Data Frame to file) </h4>  \n",
    "\n",
    "##### Write cars_df to cars_to_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.to_csv('./pandas_datasets/cars_to_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0        1            2   3   4   5\n",
      "0    1   Akshay  Mathematics  50  40  80\n",
      "1    2   Mahima      English  40  33  83\n",
      "2    3    Vikas  Mathematics  50  42  84\n",
      "3    4  Abhinav      English  40  31  78\n",
      "4    5   Mahima      Science  50  40  80\n",
      "5    6   Akshay      Science  50  49  98\n",
      "6    7  Abhinav  Mathematics  50  47  94\n",
      "7    8    Vikas      Science  50  40  80\n",
      "8    9  Abhinav      Science  50  47  94\n",
      "9   10    Vikas      English  40  39  98\n",
      "10  11   Akshay      English  40  35  88\n",
      "11  12   Mahima  Mathematics  50  43  86\n"
     ]
    }
   ],
   "source": [
    "#Marks.csv\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# The file is stored at: 'https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv'\n",
    "# Provide your answer below\n",
    "df = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv', header = None, sep = '|')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Maximum Marks</th>\n",
       "      <th>Marks Obtained</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S.No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akshay</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>English</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abhinav</td>\n",
       "      <td>English</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>Science</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Akshay</td>\n",
       "      <td>Science</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abhinav</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>Science</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abhinav</td>\n",
       "      <td>Science</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>English</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Akshay</td>\n",
       "      <td>English</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mahima</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name      Subject  Maximum Marks  Marks Obtained  Percentage\n",
       "S.No                                                                 \n",
       "1      Akshay  Mathematics             50              40          80\n",
       "2      Mahima      English             40              33          83\n",
       "3       Vikas  Mathematics             50              42          84\n",
       "4     Abhinav      English             40              31          78\n",
       "5      Mahima      Science             50              40          80\n",
       "6      Akshay      Science             50              49          98\n",
       "7     Abhinav  Mathematics             50              47          94\n",
       "8       Vikas      Science             50              40          80\n",
       "9     Abhinav      Science             50              47          94\n",
       "10      Vikas      English             40              39          98\n",
       "11     Akshay      English             40              35          88\n",
       "12     Mahima  Mathematics             50              43          86"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://media-doselect.s3.amazonaws.com/generic/A08MajL8qN4rq72EpVJbAP1Rw/marks_1.csv', sep='|',header=None) # Write your answer here\n",
    "df.columns = ['S.No','Name','Subject','Maximum Marks','Marks Obtained','Percentage']\n",
    "df=df.set_index('S.No')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  area\n",
      "138  9  9   jul  tue  85.8   48.3  313.4   3.9  18.0  42   2.7   0.0  0.36\n",
      "139  1  4   sep  tue  91.0  129.5  692.6   7.0  21.7  38   2.2   0.0  0.43\n",
      "140  2  5   sep  mon  90.9  126.5  686.5   7.0  21.9  39   1.8   0.0  0.47\n",
      "141  1  2   aug  wed  95.5   99.9  513.3  13.2  23.3  31   4.5   0.0  0.55\n",
      "142  8  6   aug  fri  90.1  108.0  529.8  12.5  21.2  51   8.9   0.0  0.61\n",
      "143  1  2   jul  sat  90.0   51.3  296.3   8.7  16.6  53   5.4   0.0  0.71\n",
      "144  2  5   aug  wed  95.5   99.9  513.3  13.2  23.8  32   5.4   0.0  0.77\n",
      "145  6  5   aug  thu  95.2  131.7  578.8  10.4  27.4  22   4.0   0.0  0.90\n",
      "147  8  3   sep  tue  84.4   73.4  671.9   3.2  24.2  28   3.6   0.0  0.96\n",
      "148  2  2   aug  tue  94.8  108.3  647.1  17.0  17.4  43   6.7   0.0  1.07\n",
      "149  8  6   sep  thu  93.7   80.9  685.2  17.9  23.7  25   4.5   0.0  1.12\n",
      "150  6  5   jun  fri  92.5   56.4  433.3   7.1  23.2  39   5.4   0.0  1.19\n",
      "151  9  9   jul  sun  90.1   68.6  355.2   7.2  24.8  29   2.2   0.0  1.36\n",
      "152  3  4   jul  sat  90.1   51.2  424.1   6.2  24.6  43   1.8   0.0  1.43\n",
      "153  5  4   sep  fri  94.3   85.1  692.3  15.9  20.1  47   4.9   0.0  1.46\n",
      "154  1  5   sep  sat  93.4  145.4  721.4   8.1  29.6  27   2.7   0.0  1.46\n",
      "155  7  4   aug  sun  94.8  108.3  647.1  17.0  16.4  47   1.3   0.0  1.56\n",
      "156  2  4   sep  sat  93.4  145.4  721.4   8.1  28.6  27   2.2   0.0  1.61\n",
      "157  2  2   aug  wed  92.1  111.2  654.1   9.6  18.4  45   3.6   0.0  1.63\n",
      "158  2  4   aug  wed  92.1  111.2  654.1   9.6  20.5  35   4.0   0.0  1.64\n"
     ]
    }
   ],
   "source": [
    "# Conditional statement in dataframes\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://cdn.upgrad.com/uploads/production/b3467ba4-4e13-44e9-8087-4d7e94cc7586/forestfires.csv')\n",
    "df_2 = df.loc[(df.area>0)&(df.temp>15)&(df.wind>1),:]\n",
    "print(df_2.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "0     1     5\n",
      "1     2     6\n",
      "2     3     7\n",
      "3     4     8\n",
      "   col1  col2\n",
      "0    11    15\n",
      "1    12    16\n",
      "2    13    17\n",
      "3    14    18\n",
      "   col1  col2\n",
      "0     1     5\n",
      "1     2     6\n",
      "2     3     7\n",
      "3     4     8\n",
      "   col1\n",
      "0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "   col1  col2   col3 col4\n",
      "0     1     5   True    a\n",
      "1     2     6  False    b\n",
      "2     3     7  False    c\n",
      "3     4     8   True    d\n",
      "   col1  col2   col3 col4\n",
      "0    11    15   True    e\n",
      "1    12    16  False    f\n",
      "2    13    17   True    g\n",
      "3    14    18  False    h\n",
      "   col1  col2   col3 col4\n",
      "0     1     5   True    a\n",
      "1     2     6  False    b\n",
      "2     3     7  False    c\n",
      "3     4     8   True    d\n",
      "    col1 col2  col3  col4\n",
      "0   True    e    11    15\n",
      "1  False    f    12    16\n",
      "2   True    g    13    17\n",
      "3  False    h    14    18\n"
     ]
    }
   ],
   "source": [
    "### Create DataFrames \n",
    "\n",
    "#Since a new concept is being introduced, it is beneficial to explore the concept first using simple DataFrames. Once you understand the usage and the capabilities of these concepts, you can think of ways to apply these capabilities as and when needed. \n",
    " \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_1 = {\"col1\":[1,2,3,4], \"col2\": [5,6,7,8]}\n",
    "df_2 = {\"col1\":[11,12,13,14], \"col2\": [15,16,17,18]}\n",
    "\n",
    "df1 = pd.DataFrame(df_1)\n",
    "df2 = pd.DataFrame(df_2)\n",
    "\n",
    "df1\n",
    "\n",
    "df2\n",
    "\n",
    "### Concatenation \n",
    "\n",
    "# It is used when you want to stick two dataframes together without any consideration given to matching elements. In contrast, the merge command uses a key to stitch two data frames together. \n",
    "\n",
    "# If the shape of the two concatenating dataframes does not match, NaN values are added to make the dimensions uniform. \n",
    "\n",
    "\n",
    "pd.concat([df1, df2], axis = 0)\n",
    "\n",
    "# Axis 0 represents row wise concatenation\n",
    "\n",
    "# **NOTE**\n",
    "\n",
    "# - Rows in df2 get added to the df1\n",
    "# - Intexes of df2 remain the same as they were before the join. \n",
    "\n",
    "pd.concat([df1, df2], axis = 1)\n",
    "\n",
    "# Axis 0 represents column wise concatenation\n",
    "\n",
    "df1[\"col3\"] = df1[\"col1\"] + df1[\"col2\"]\n",
    "\n",
    "# After this operation df1 will have 3 columns while df2 has only 2. \n",
    "\n",
    "pd.concat([df1, df2], axis = 0)\n",
    "\n",
    "# Since there is one extra column in df1, the corresponding vales in df2 become `NaN` or null values. \n",
    "\n",
    "# ### Arithmetic Operators on DataFrames\n",
    "\n",
    "# You can perform element wise operations on dataframes as well. These are very similar to operations you performed on NumPy arrays. \n",
    "\n",
    "# for example, if you want to add all the elements on `df1` to the correspopnding elements on `df2` you can use the '+' operator. \n",
    "\n",
    "df1 + df2 \n",
    "\n",
    "# As you saw all the elements in `df1` got added to corresponding elements in `df2`\n",
    " \n",
    "# But the `df1` had three columns while `df2` had two. So the operation for the third column is incomplete, that is why you see the null values in the result. This is the most significant difference in using operators in pandas and NumPy; this operation would have thrown an error if it was executed using NumPy arrays.  \n",
    "\n",
    "# The same result can be achieved by the `add()` method\n",
    "\n",
    "# df1.add(df2)\n",
    "\n",
    "# Along with the normal addition this add method also provides additional functionalities. You can read about them [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.add.html)\n",
    "\n",
    "# similar to the '+' operator and the `add()` there are other operators as well \n",
    "\n",
    "# - `sub()`: ' - '\n",
    "# - `mul()`: ' * '\n",
    "# - `div()`: ' / '\n",
    "# - `floordiv()`: ' // '\n",
    "# - `mod()`: ' % ' \n",
    "# - `pow()`: ' ** '\n",
    "\n",
    "# recreating the DataFrames so that the dimentions match. \n",
    "\n",
    "df_1 = {\"col1\":[1,2,3,4], \"col2\": [5,6,7,8]}\n",
    "df_2 = {\"col1\":[11,12,13,14], \"col2\": [15,16,17,18]}\n",
    "\n",
    "df1 = pd.DataFrame(df_1)\n",
    "df2 = pd.DataFrame(df_2)\n",
    "\n",
    "print (df1)\n",
    "print (df2)\n",
    "\n",
    "df2 - df1\n",
    "\n",
    "df2 ** df1\n",
    "\n",
    "# recreating the DataFrames so that the dimentions match. \n",
    "\n",
    "df_1 = {\"col1\":[1,2,3,4], \"col2\": [5,6,7,8]}\n",
    "df_2 = {\"col1\":[11,12,13,14]}\n",
    "\n",
    "df1 = pd.DataFrame(df_1)\n",
    "df2 = pd.DataFrame(df_2)\n",
    "\n",
    "print (df1)\n",
    "print (df2)\n",
    "\n",
    "df1 + df2\n",
    "\n",
    "# One of the advantages of pandas DataFrame is that it can hold data of different data types. \n",
    " \n",
    "# Which leads us to the question What would happen of operators were used on DataFrames which have \"non-numerical\" data types?\n",
    "\n",
    "df_1 = {\"col1\":[1,2,3,4], \"col2\": [5,6,7,8], \"col3\": [True,False,False,True], \"col4\": [\"a\",\"b\",\"c\",\"d\"] }\n",
    "df_2 = {\"col1\":[11,12,13,14], \"col2\": [15,16,17,18], \"col3\": [True,False,True,False], \"col4\": [\"e\",\"f\",\"g\",\"h\"]}\n",
    "\n",
    "df1 = pd.DataFrame(df_1)\n",
    "df2 = pd.DataFrame(df_2)\n",
    "\n",
    "print (df1)\n",
    "print (df2)\n",
    "\n",
    "df1 +df2 \n",
    "\n",
    "# Something very interesting has happened. \n",
    " \n",
    "# Pandas was smart enough to recognise the different data types and use the operators accordingly. \n",
    " \n",
    "# - For int data type, it performed addition \n",
    "# - For boolean, it performed OR operation\n",
    "# - For string, it performed concatenation \n",
    "\n",
    "# The below expression throws an error because there is not '-' in strings and pandas cannot figure out what to do. \n",
    "# df1 - df2\n",
    "\n",
    "\n",
    "df_1 = {\"col1\":[1,2,3,4], \"col2\": [5,6,7,8], \"col3\": [True,False,False,True], \"col4\": [\"a\",\"b\",\"c\",\"d\"] }\n",
    "df_2 = {\"col1\": [True,False,True,False], \"col2\": [\"e\",\"f\",\"g\",\"h\"], \"col3\":[11,12,13,14], \"col4\": [15,16,17,18] }\n",
    "\n",
    "df1 = pd.DataFrame(df_1)\n",
    "df2 = pd.DataFrame(df_2)\n",
    "\n",
    "print (df1)\n",
    "print (df2)\n",
    "\n",
    "# Since the data types of correcponding columns do not match Pandas throws a type error for the below expression\n",
    "# df1 + df2\n",
    "\n",
    "\n",
    "# ### Summary\n",
    "\n",
    "# ##### 1. `Concatenation` : Used when you want to stich to dataframes together without any reguard to the values. \n",
    "# a. Even if the shapes do not match the operation is performed. Filling Null values wherever necessary. \n",
    "# ##### 2. `operators` : Can perform element wise operations on Pandas DataFrames. \n",
    "# a. You can use operators themselves '+' or the function `add()` for the same result.  \n",
    "# b. If the Shape does not match then null values are added. \n",
    "# c. Can work with differnet data types as well, as long as the operation is defined for that data type. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style = \"color : Brown\"> Operations on Pandas</h2>\n",
    "<a id='Operations_on_Pandas'>Operations_on_Pandas</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Practice_exercise_1'>Practice_exercise_1</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>actor_2_facebook_likes</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.78</td>\n",
       "      <td>33000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>302.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Orlando Bloom</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>309404152.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>602.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>Rory Kinnear</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>200074175.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>994.0</td>\n",
       "      <td>English</td>\n",
       "      <td>UK</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>245000000.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.35</td>\n",
       "      <td>85000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>813.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>448130642.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.35</td>\n",
       "      <td>164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>462.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>Samantha Morton</td>\n",
       "      <td>640.0</td>\n",
       "      <td>73058679.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>738.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>263700000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.35</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>Color</td>\n",
       "      <td>Shane Carruth</td>\n",
       "      <td>143.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>David Sullivan</td>\n",
       "      <td>291.0</td>\n",
       "      <td>424760.0</td>\n",
       "      <td>Drama|Sci-Fi|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>371.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Color</td>\n",
       "      <td>Neill Dela Llana</td>\n",
       "      <td>35.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Edgar Tancangco</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70071.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>English</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>Color</td>\n",
       "      <td>Robert Rodriguez</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peter Marquardt</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2040920.0</td>\n",
       "      <td>Action|Crime|Drama|Romance|Thriller</td>\n",
       "      <td>...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>USA</td>\n",
       "      <td>R</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>Color</td>\n",
       "      <td>Edward Burns</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>Caitlin FitzGerald</td>\n",
       "      <td>296.0</td>\n",
       "      <td>4584.0</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>Color</td>\n",
       "      <td>Jon Gunn</td>\n",
       "      <td>43.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Brian Herzlinger</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85222.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>PG</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3853 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color      director_name  num_critic_for_reviews  duration  \\\n",
       "0     Color      James Cameron                   723.0     178.0   \n",
       "1     Color     Gore Verbinski                   302.0     169.0   \n",
       "2     Color         Sam Mendes                   602.0     148.0   \n",
       "3     Color  Christopher Nolan                   813.0     164.0   \n",
       "4     Color     Andrew Stanton                   462.0     132.0   \n",
       "...     ...                ...                     ...       ...   \n",
       "3848  Color      Shane Carruth                   143.0      77.0   \n",
       "3849  Color   Neill Dela Llana                    35.0      80.0   \n",
       "3850  Color   Robert Rodriguez                    56.0      81.0   \n",
       "3851  Color       Edward Burns                    14.0      95.0   \n",
       "3852  Color           Jon Gunn                    43.0      90.0   \n",
       "\n",
       "      director_facebook_likes  actor_3_facebook_likes        actor_2_name  \\\n",
       "0                         0.0                   855.0    Joel David Moore   \n",
       "1                       563.0                  1000.0       Orlando Bloom   \n",
       "2                         0.0                   161.0        Rory Kinnear   \n",
       "3                     22000.0                 23000.0      Christian Bale   \n",
       "4                       475.0                   530.0     Samantha Morton   \n",
       "...                       ...                     ...                 ...   \n",
       "3848                    291.0                     8.0      David Sullivan   \n",
       "3849                      0.0                     0.0     Edgar Tancangco   \n",
       "3850                      0.0                     6.0     Peter Marquardt   \n",
       "3851                      0.0                   133.0  Caitlin FitzGerald   \n",
       "3852                     16.0                    16.0    Brian Herzlinger   \n",
       "\n",
       "      actor_1_facebook_likes        gross  \\\n",
       "0                     1000.0  760505847.0   \n",
       "1                    40000.0  309404152.0   \n",
       "2                    11000.0  200074175.0   \n",
       "3                    27000.0  448130642.0   \n",
       "4                      640.0   73058679.0   \n",
       "...                      ...          ...   \n",
       "3848                   291.0     424760.0   \n",
       "3849                     0.0      70071.0   \n",
       "3850                   121.0    2040920.0   \n",
       "3851                   296.0       4584.0   \n",
       "3852                    86.0      85222.0   \n",
       "\n",
       "                                   genres  ... num_user_for_reviews language  \\\n",
       "0         Action|Adventure|Fantasy|Sci-Fi  ...               3054.0  English   \n",
       "1                Action|Adventure|Fantasy  ...               1238.0  English   \n",
       "2               Action|Adventure|Thriller  ...                994.0  English   \n",
       "3                         Action|Thriller  ...               2701.0  English   \n",
       "4                 Action|Adventure|Sci-Fi  ...                738.0  English   \n",
       "...                                   ...  ...                  ...      ...   \n",
       "3848                Drama|Sci-Fi|Thriller  ...                371.0  English   \n",
       "3849                             Thriller  ...                 35.0  English   \n",
       "3850  Action|Crime|Drama|Romance|Thriller  ...                130.0  Spanish   \n",
       "3851                         Comedy|Drama  ...                 14.0  English   \n",
       "3852                          Documentary  ...                 84.0  English   \n",
       "\n",
       "          country  content_rating       budget  title_year  \\\n",
       "0             USA           PG-13  237000000.0      2009.0   \n",
       "1             USA           PG-13  300000000.0      2007.0   \n",
       "2              UK           PG-13  245000000.0      2015.0   \n",
       "3             USA           PG-13  250000000.0      2012.0   \n",
       "4             USA           PG-13  263700000.0      2012.0   \n",
       "...           ...             ...          ...         ...   \n",
       "3848          USA           PG-13       7000.0      2004.0   \n",
       "3849  Philippines       Not Rated       7000.0      2005.0   \n",
       "3850          USA               R       7000.0      1992.0   \n",
       "3851          USA       Not Rated       9000.0      2011.0   \n",
       "3852          USA              PG       1100.0      2004.0   \n",
       "\n",
       "     actor_2_facebook_likes imdb_score  aspect_ratio movie_facebook_likes  \n",
       "0                     936.0        7.9          1.78                33000  \n",
       "1                    5000.0        7.1          2.35                    0  \n",
       "2                     393.0        6.8          2.35                85000  \n",
       "3                   23000.0        8.5          2.35               164000  \n",
       "4                     632.0        6.6          2.35                24000  \n",
       "...                     ...        ...           ...                  ...  \n",
       "3848                   45.0        7.0          1.85                19000  \n",
       "3849                    0.0        6.3           NaN                   74  \n",
       "3850                   20.0        6.9          1.37                    0  \n",
       "3851                  205.0        6.4           NaN                  413  \n",
       "3852                   23.0        6.6          1.85                  456  \n",
       "\n",
       "[3853 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(3853, 28)\n",
      "color                         2\n",
      "director_name                 0\n",
      "num_critic_for_reviews        1\n",
      "duration                      1\n",
      "director_facebook_likes       0\n",
      "actor_3_facebook_likes        6\n",
      "actor_2_name                  1\n",
      "actor_1_facebook_likes        0\n",
      "gross                         0\n",
      "genres                        0\n",
      "actor_1_name                  0\n",
      "movie_title                   0\n",
      "num_voted_users               0\n",
      "cast_total_facebook_likes     0\n",
      "actor_3_name                  6\n",
      "facenumber_in_poster          6\n",
      "plot_keywords                30\n",
      "movie_imdb_link               0\n",
      "num_user_for_reviews          0\n",
      "language                      4\n",
      "country                       0\n",
      "content_rating               48\n",
      "budget                        0\n",
      "title_year                    0\n",
      "actor_2_facebook_likes        1\n",
      "imdb_score                    0\n",
      "aspect_ratio                 72\n",
      "movie_facebook_likes          0\n",
      "dtype: int64\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "3671\n",
      "3675\n",
      "color                         object\n",
      "director_name                 object\n",
      "num_critic_for_reviews       float64\n",
      "duration                     float64\n",
      "director_facebook_likes      float64\n",
      "actor_3_facebook_likes       float64\n",
      "actor_2_name                  object\n",
      "actor_1_facebook_likes       float64\n",
      "gross                        float64\n",
      "genres                        object\n",
      "actor_1_name                  object\n",
      "movie_title                   object\n",
      "num_voted_users                int64\n",
      "cast_total_facebook_likes      int64\n",
      "actor_3_name                  object\n",
      "facenumber_in_poster         float64\n",
      "plot_keywords                 object\n",
      "movie_imdb_link               object\n",
      "num_user_for_reviews         float64\n",
      "language                      object\n",
      "country                       object\n",
      "content_rating                object\n",
      "budget                       float64\n",
      "title_year                   float64\n",
      "actor_2_facebook_likes       float64\n",
      "imdb_score                   float64\n",
      "aspect_ratio                 float64\n",
      "movie_facebook_likes           int64\n",
      "dtype: object\n",
      "Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',\n",
      "       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',\n",
      "       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',\n",
      "       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',\n",
      "       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',\n",
      "       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',\n",
      "       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',\n",
      "       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],\n",
      "      dtype='object')\n",
      "11\n",
      "(3853, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545/4135813292.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  movies[\"language\"].fillna(\"English\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "director_name             0.000000\n",
       "num_critic_for_reviews    0.025954\n",
       "gross                     0.000000\n",
       "genres                    0.000000\n",
       "actor_1_name              0.000000\n",
       "movie_title               0.000000\n",
       "num_voted_users           0.000000\n",
       "num_user_for_reviews      0.000000\n",
       "language                  0.000000\n",
       "budget                    0.000000\n",
       "title_year                0.000000\n",
       "imdb_score                0.000000\n",
       "movie_facebook_likes      0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_critic_for_reviews\n",
      "3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545/4135813292.py:74: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  movies[\"language\"].fillna(\"English\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.0</td>\n",
       "      <td>760.505847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.0</td>\n",
       "      <td>309.404152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245.0</td>\n",
       "      <td>200.074175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250.0</td>\n",
       "      <td>448.130642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.7</td>\n",
       "      <td>73.058679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   budget       gross\n",
       "0   237.0  760.505847\n",
       "1   300.0  309.404152\n",
       "2   245.0  200.074175\n",
       "3   250.0  448.130642\n",
       "4   263.7   73.058679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>actor_1_name</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>num_user_for_reviews</th>\n",
       "      <th>language</th>\n",
       "      <th>budget</th>\n",
       "      <th>title_year</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>movie_facebook_likes</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>760.505847</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>CCH Pounder</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>886204</td>\n",
       "      <td>3054.0</td>\n",
       "      <td>English</td>\n",
       "      <td>237.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>33000</td>\n",
       "      <td>523.505847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>644.0</td>\n",
       "      <td>652.177271</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>Bryce Dallas Howard</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>418214</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>English</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>150000</td>\n",
       "      <td>502.177271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>James Cameron</td>\n",
       "      <td>315.0</td>\n",
       "      <td>658.672302</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>Leonardo DiCaprio</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>793059</td>\n",
       "      <td>2528.0</td>\n",
       "      <td>English</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26000</td>\n",
       "      <td>458.672302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>George Lucas</td>\n",
       "      <td>282.0</td>\n",
       "      <td>460.935665</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>Harrison Ford</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope</td>\n",
       "      <td>911097</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>English</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>33000</td>\n",
       "      <td>449.935665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>Steven Spielberg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>434.949459</td>\n",
       "      <td>Family|Sci-Fi</td>\n",
       "      <td>Henry Thomas</td>\n",
       "      <td>E.T. the Extra-Terrestrial</td>\n",
       "      <td>281842</td>\n",
       "      <td>515.0</td>\n",
       "      <td>English</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>34000</td>\n",
       "      <td>424.449459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>703.0</td>\n",
       "      <td>623.279547</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>Chris Hemsworth</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>995415</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>English</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>123000</td>\n",
       "      <td>403.279547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Roger Allers</td>\n",
       "      <td>186.0</td>\n",
       "      <td>422.783777</td>\n",
       "      <td>Adventure|Animation|Drama|Family|Musical</td>\n",
       "      <td>Matthew Broderick</td>\n",
       "      <td>The Lion King</td>\n",
       "      <td>644348</td>\n",
       "      <td>656.0</td>\n",
       "      <td>English</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17000</td>\n",
       "      <td>377.783777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>George Lucas</td>\n",
       "      <td>320.0</td>\n",
       "      <td>474.544677</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>Natalie Portman</td>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>534658</td>\n",
       "      <td>3597.0</td>\n",
       "      <td>English</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>13000</td>\n",
       "      <td>359.544677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>645.0</td>\n",
       "      <td>533.316061</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>Christian Bale</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>1676169</td>\n",
       "      <td>4667.0</td>\n",
       "      <td>English</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37000</td>\n",
       "      <td>348.316061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Gary Ross</td>\n",
       "      <td>673.0</td>\n",
       "      <td>407.999255</td>\n",
       "      <td>Adventure|Drama|Sci-Fi|Thriller</td>\n",
       "      <td>Jennifer Lawrence</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>701607</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>English</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>140000</td>\n",
       "      <td>329.999255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          director_name  num_critic_for_reviews       gross  \\\n",
       "0         James Cameron                   723.0  760.505847   \n",
       "28      Colin Trevorrow                   644.0  652.177271   \n",
       "25        James Cameron                   315.0  658.672302   \n",
       "2704       George Lucas                   282.0  460.935665   \n",
       "2748   Steven Spielberg                   215.0  434.949459   \n",
       "16          Joss Whedon                   703.0  623.279547   \n",
       "482        Roger Allers                   186.0  422.783777   \n",
       "230        George Lucas                   320.0  474.544677   \n",
       "64    Christopher Nolan                   645.0  533.316061   \n",
       "419           Gary Ross                   673.0  407.999255   \n",
       "\n",
       "                                        genres         actor_1_name  \\\n",
       "0              Action|Adventure|Fantasy|Sci-Fi          CCH Pounder   \n",
       "28            Action|Adventure|Sci-Fi|Thriller  Bryce Dallas Howard   \n",
       "25                               Drama|Romance    Leonardo DiCaprio   \n",
       "2704           Action|Adventure|Fantasy|Sci-Fi        Harrison Ford   \n",
       "2748                             Family|Sci-Fi         Henry Thomas   \n",
       "16                     Action|Adventure|Sci-Fi      Chris Hemsworth   \n",
       "482   Adventure|Animation|Drama|Family|Musical    Matthew Broderick   \n",
       "230            Action|Adventure|Fantasy|Sci-Fi      Natalie Portman   \n",
       "64                 Action|Crime|Drama|Thriller       Christian Bale   \n",
       "419            Adventure|Drama|Sci-Fi|Thriller    Jennifer Lawrence   \n",
       "\n",
       "                                     movie_title  num_voted_users  \\\n",
       "0                                        Avatar           886204   \n",
       "28                               Jurassic World           418214   \n",
       "25                                      Titanic           793059   \n",
       "2704         Star Wars: Episode IV - A New Hope           911097   \n",
       "2748                 E.T. the Extra-Terrestrial           281842   \n",
       "16                                 The Avengers           995415   \n",
       "482                               The Lion King           644348   \n",
       "230   Star Wars: Episode I - The Phantom Menace           534658   \n",
       "64                              The Dark Knight          1676169   \n",
       "419                            The Hunger Games           701607   \n",
       "\n",
       "      num_user_for_reviews language  budget  title_year  imdb_score  \\\n",
       "0                   3054.0  English   237.0      2009.0         7.9   \n",
       "28                  1290.0  English   150.0      2015.0         7.0   \n",
       "25                  2528.0  English   200.0      1997.0         7.7   \n",
       "2704                1470.0  English    11.0      1977.0         8.7   \n",
       "2748                 515.0  English    10.5      1982.0         7.9   \n",
       "16                  1722.0  English   220.0      2012.0         8.1   \n",
       "482                  656.0  English    45.0      1994.0         8.5   \n",
       "230                 3597.0  English   115.0      1999.0         6.5   \n",
       "64                  4667.0  English   185.0      2008.0         9.0   \n",
       "419                 1959.0  English    78.0      2012.0         7.3   \n",
       "\n",
       "      movie_facebook_likes      profit  \n",
       "0                    33000  523.505847  \n",
       "28                  150000  502.177271  \n",
       "25                   26000  458.672302  \n",
       "2704                 33000  449.935665  \n",
       "2748                 34000  424.449459  \n",
       "16                  123000  403.279547  \n",
       "482                  17000  377.783777  \n",
       "230                  13000  359.544677  \n",
       "64                   37000  348.316061  \n",
       "419                 140000  329.999255  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m display(top10)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Question 6: Which movie is ranked 5th from the top in the list obtained?\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Based on the sorted dataframe, this should be:\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtop10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Get the title of the 5th movie\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Subtask 3.3: Find IMDb Top 250\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Filter movies that have a num_voted_users greater than 25,000 and sort by imdb_score\u001b[39;00m\n\u001b[1;32m    110\u001b[0m IMDb_Top_250 \u001b[38;5;241m=\u001b[39m movies[movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_voted_users\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m25000\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_score\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m250\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Task 1: Reading and Inspection\n",
    "\n",
    "# Subtask 1.1: Import and read the dataset\n",
    "movies = pd.read_csv(\"./pandas_datasets/Movies.csv\")\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "display(movies)\n",
    "\n",
    "# Check the number of missing values across the columns\n",
    "print((movies.isnull().sum() > 0).sum())  # Count of columns with missing values\n",
    "print(movies.shape)  # Shape of the dataframe\n",
    "print(movies.isnull().sum())  # Missing values per column\n",
    "print(movies[\"language\"].isnull().sum())  # Missing values in language column\n",
    "print(movies[\"genres\"].isnull().sum())  # Missing values in genres column\n",
    "print(movies[\"num_critic_for_reviews\"].isnull().sum())  # Missing values in critic reviews column\n",
    "print(movies[\"imdb_score\"].isnull().sum())  # Missing values in imdb_score column\n",
    "\n",
    "# Count movies with English language\n",
    "print(len(movies[movies[\"language\"] == \"English\"]))\n",
    "\n",
    "# Fill missing language values with 'English'\n",
    "movies[\"language\"].fillna(\"English\", inplace=True)\n",
    "\n",
    "# Count movies with English language after filling missing values\n",
    "print(len(movies[movies[\"language\"] == \"English\"]))\n",
    "\n",
    "# Subtask 1.2: Inspect the dataframe\n",
    "# Show the data types of each column\n",
    "print(movies.dtypes)\n",
    "\n",
    "# Show the column names\n",
    "print(movies.columns)\n",
    "\n",
    "# Question 1: How many rows and columns are present in the dataframe?\n",
    "# Answer: The shape of the dataframe is (3879, 28)\n",
    "# Based on the shape information from above, we know the answer is (3879, 28).\n",
    "\n",
    "# Question 2: How many columns have null values present in them?\n",
    "# The count of columns with missing values can be calculated using the following code:\n",
    "print((movies.isnull().sum() > 0).sum())  # This will return the number of columns with null values.\n",
    "\n",
    "# Task 2: Cleaning the Data\n",
    "\n",
    "# Subtask 2.1: Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    \"color\", \"director_facebook_likes\", \"actor_1_facebook_likes\", \n",
    "    \"actor_2_facebook_likes\", \"actor_3_facebook_likes\", \"actor_2_name\", \n",
    "    \"cast_total_facebook_likes\", \"actor_3_name\", \"duration\", \"facenumber_in_poster\", \n",
    "    \"content_rating\", \"country\", \"movie_imdb_link\", \"aspect_ratio\", \"plot_keywords\"\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "movies.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Display the new shape of the dataframe\n",
    "print(movies.shape)  # Question 3: The count of columns in the new dataframe will be 15.\n",
    "\n",
    "# Subtask 2.2: Inspect Null values\n",
    "# Calculate the percentage of missing values in each column\n",
    "null_percentages = movies.isnull().mean() * 100\n",
    "display(null_percentages)\n",
    "\n",
    "# Question 4: Which column has the highest percentage of null values?\n",
    "# You can find the column with the highest percentage of null values by sorting the null percentages:\n",
    "print(null_percentages.idxmax())  # This will give the column name with the highest null percentage\n",
    "\n",
    "# Subtask 2.3: Fill NaN values\n",
    "# As discussed, we will fill the missing values in the 'language' column with \"English\".\n",
    "movies[\"language\"].fillna(\"English\", inplace=True)\n",
    "\n",
    "# Question 5: What is the count of movies made in English after replacing the NaN values with English?\n",
    "print(len(movies[movies[\"language\"] == \"English\"]))  # Answer: 3674\n",
    "\n",
    "# Task 3: Data Analysis\n",
    "\n",
    "# Subtask 3.1: Change the unit of columns\n",
    "# Convert the 'budget' and 'gross' columns from dollars to millions of dollars.\n",
    "movies['budget'] = movies['budget'] / 1e6\n",
    "movies['gross'] = movies['gross'] / 1e6\n",
    "\n",
    "# Display the updated columns\n",
    "display(movies[['budget', 'gross']].head())\n",
    "\n",
    "# Subtask 3.2: Find the movies with the highest profit\n",
    "\n",
    "# Create a new column called 'profit' as the difference between 'gross' and 'budget'\n",
    "movies['profit'] = movies['gross'] - movies['budget']\n",
    "\n",
    "# Sort the dataframe by 'profit' in descending order\n",
    "movies_sorted_by_profit = movies.sort_values(by='profit', ascending=False)\n",
    "\n",
    "# Extract the top 10 profiting movies\n",
    "top10 = movies_sorted_by_profit.head(10)\n",
    "\n",
    "# Display the top 10 profiting movies\n",
    "display(top10)\n",
    "\n",
    "# Question 6: Which movie is ranked 5th from the top in the list obtained?\n",
    "# Based on the sorted dataframe, this should be:\n",
    "print(top10.iloc[4]['title'])  # Get the title of the 5th movie\n",
    "\n",
    "# Subtask 3.3: Find IMDb Top 250\n",
    "\n",
    "# Filter movies that have a num_voted_users greater than 25,000 and sort by imdb_score\n",
    "IMDb_Top_250 = movies[movies['num_voted_users'] > 25000].sort_values(by='imdb_score', ascending=False).head(250)\n",
    "\n",
    "# Add a 'Rank' column to IMDb_Top_250\n",
    "IMDb_Top_250['Rank'] = range(1, 251)\n",
    "\n",
    "# Display the IMDb Top 250 dataframe\n",
    "display(IMDb_Top_250)\n",
    "\n",
    "# Question 7: Which bucket holds the maximum number of movies from IMDb_Top_250?\n",
    "# Create buckets based on the 'imdb_score' column\n",
    "buckets = pd.cut(IMDb_Top_250['imdb_score'], bins=[7.5, 8, 8.5, 9, 9.5, 10])\n",
    "\n",
    "# Count the number of movies in each bucket\n",
    "bucket_counts = buckets.value_counts()\n",
    "\n",
    "# Display the bucket with the maximum count\n",
    "print(bucket_counts.idxmax())  # This will print the range with the most movies\n",
    "\n",
    "# Subtask 3.4: Find the critic-favorite and audience-favorite actors\n",
    "\n",
    "# Create dataframes for Meryl Streep, Leonardo DiCaprio, and Brad Pitt\n",
    "Meryl_Streep = movies[movies['actor_1_name'] == 'Meryl Streep']\n",
    "Leo_Caprio = movies[movies['actor_1_name'] == 'Leonardo DiCaprio']\n",
    "Brad_Pitt = movies[movies['actor_1_name'] == 'Brad Pitt']\n",
    "\n",
    "# Combine the three dataframes into one\n",
    "Combined = pd.concat([Meryl_Streep, Leo_Caprio, Brad_Pitt])\n",
    "\n",
    "# Group by actor and calculate the mean of critic and user reviews\n",
    "combined_grouped = Combined.groupby('actor_1_name').agg(\n",
    "    mean_critic_reviews=('num_critic_for_reviews', 'mean'),\n",
    "    mean_user_reviews=('num_user_for_reviews', 'mean')\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "display(combined_grouped)\n",
    "\n",
    "# Question 8: Which actor is highest rated among the three actors according to the user reviews?\n",
    "# Answer: The actor with the highest mean user reviews\n",
    "highest_rated_user = combined_grouped['mean_user_reviews'].idxmax()\n",
    "print(highest_rated_user)\n",
    "\n",
    "# Question 9: Which actor is highest rated among the three actors according to the critics?\n",
    "# Answer: The actor with the highest mean critic reviews\n",
    "highest_rated_critic = combined_grouped['mean_critic_reviews'].idxmax()\n",
    "print(highest_rated_critic)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Seoul_dataset'>Seoul_dataset</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pandas_datasets/Measurement_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m####  Seoul dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Question\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# You can download the dataset from kaggle website: https://www.kaggle.com/bappekim/air-pollution-in-seoul\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pandas_datasets/Measurement_info.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m data\n\u001b[1;32m     19\u001b[0m item \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pandas_datasets/Measurement_item_info.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pandas_datasets/Measurement_info.csv'"
     ]
    }
   ],
   "source": [
    "####  Seoul dataset\n",
    "#Question\n",
    "\n",
    "# The air quality data for this segment has been divided into three different csv files. \n",
    "\n",
    "# `info.csv` has the data hour by hour data about the concentration of polutants in the air and the status of the intruments. \n",
    "# `item_info` has the data for items and levels of concetration. \n",
    "# `station_info` has the data for measutring stations. \n",
    "\n",
    "# Read in all the three datasets and then print the first five rows.\n",
    "\n",
    "# You can download the dataset from kaggle website: https://www.kaggle.com/bappekim/air-pollution-in-seoul\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./pandas_datasets/Measurement_info.csv\", header = 0)\n",
    "data\n",
    "\n",
    "item = pd.read_csv(\"./pandas_datasets/Measurement_item_info.csv\", header = 0)\n",
    "item\n",
    "\n",
    "station = pd.read_csv(\"./pandas_datasets/Measurement_station_info.csv\", header = 0)\n",
    "station\n",
    "\n",
    "#### Question\n",
    "\n",
    "# Create a new Dataframe whcih has information about the item code and item name\n",
    "\n",
    "sub_item = item[['Item code', 'Item name']]\n",
    "sub_item\n",
    "\n",
    "#### Question\n",
    "\n",
    "# Create a new Dataframe whcih has information about the station code and station name\n",
    "\n",
    "sub_station = station[['Station code', 'Station name(district)']]\n",
    "sub_station\n",
    "\n",
    "### Question \n",
    "\n",
    "# In the `data` DataFrame add in a column displaying the names of the items. \n",
    "\n",
    "data_i = data.merge(sub_item, on = \"Item code\", how = \"left\")\n",
    "data_i.head()\n",
    "\n",
    "### Question \n",
    "\n",
    "# In the `data_i` DataFrame add in a column displaying the names of the stations. \n",
    "\n",
    "data_s = data_i.merge(sub_station, on = \"Station code\", how = \"left\")\n",
    "data_s.head()\n",
    "\n",
    "### Question \n",
    "\n",
    "# In the `data_s` DataFrame drop the columns `Station code` and `Item code`. As these columns have not become redundant. You can find the relevant function in the pandas library [here](https://pandas.pydata.org/docs/reference/index.html). \n",
    "\n",
    "data = data_s.drop(['Station code', 'Item code'], axis = 1)\n",
    "data.head()\n",
    "\n",
    "### Question \n",
    "\n",
    "# Given below are the meanings of the values in the `Instrument status`. \n",
    "\n",
    "# - 0: Normal \n",
    "# - 1: Need for calibration \n",
    "# - 2: Abnormal\n",
    "# - 4: Power cut off \n",
    "# - 8: Under repair\n",
    "# - 9: Abnormal data\n",
    "\n",
    "# Using the information given above, add a column in the `data` DataFrame to give the status of the intsruments. Then drop the `Instrument status` column.  \n",
    "\n",
    "# Hint: First create a dictionary from the data, then use the same dictionary to create a DataFrame and then merge the DataFrame. with `data`\n",
    "\n",
    "status_dict = {\"Instrument status\": [0,1,2,4,8,9], \n",
    "               \"Status\": [\"Normal\", \"Need for calibration\", \"Abnormal\", \"Power cut off\", \"Under repair\", \"Abnormal data\"]}\n",
    "status_dict\n",
    "\n",
    "dictdf = pd.DataFrame(status_dict)\n",
    "dictdf\n",
    "\n",
    "data = data.merge(dictdf, on = \"Instrument status\", how = \"left\")\n",
    "\n",
    "data.head()\n",
    "\n",
    "data = data.drop([\"Instrument status\"], axis = 1)\n",
    "\n",
    "data.head()\n",
    "\n",
    "### Question \n",
    "\n",
    "# Extract the time series data, that is year, month, date and hour form the `Measurement date` column. Once all the data is extrcted drop the `Measurement date` column. \n",
    "\n",
    "# This operation might take some time as the dataset we are working with is very large. \n",
    "\n",
    "data['Year'] = pd.DatetimeIndex(data['Measurement date']).year\n",
    "data['Month'] = pd.DatetimeIndex(data['Measurement date']).month\n",
    "data['Date'] = pd.DatetimeIndex(data['Measurement date']).day\n",
    "data['Hour'] = pd.DatetimeIndex(data['Measurement date']).hour\n",
    "data.head()\n",
    "\n",
    "data = data.drop([\"Measurement date\"], axis =1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Sales_dataset'>Sales_dataset</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('''\n",
    "<h2 style = \"color : Brown\">Case Study - Sales Data </h2>\n",
    "'''))\n",
    "\n",
    "# All imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "##### Sales and Profit data is read in dataframe \"sales\"\n",
    "\n",
    "# Read file \n",
    "\n",
    "sales = pd.read_excel('sales.xlsx')\n",
    "sales\n",
    "\n",
    "# Read file and set 1st two columns as index\n",
    "sales = pd.read_excel('sales.xlsx', index_col = [0,1])\n",
    "\n",
    "sales\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 1</h4>  \n",
    "'''))\n",
    "\n",
    "##### Display first 3 land last 3 rows of the sales dataframe\n",
    "\n",
    "\n",
    "sales.head() # Default - returns top 5 rows\n",
    "\n",
    "sales.head(3)\n",
    "\n",
    "sales.tail()\n",
    "\n",
    "sales.tail(3)\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 2</h4>   \n",
    "'''))\n",
    "\n",
    "##### Display the information about the data stored in data frame\n",
    "\n",
    "\n",
    "sales.info()\n",
    "\n",
    "##### Display the statistical information about the data in dataframe\n",
    "\n",
    "sales.describe()\n",
    "\n",
    "sales[[\"Sales\", \"Profit\"]].plot(kind= \"box\", subplots= True)\n",
    "plt.show()\n",
    "\n",
    "sales[\"Profit\"]\n",
    "\n",
    "\n",
    "##########################################################################################################3\n",
    "display(HTML('''\n",
    "<h2 style = \"color : Brown\">Case Study - Sales Data </h2>\n",
    "'''))\n",
    "\n",
    "# All imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Displays pandas float values in 2 decimals\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "sales = pd.read_excel('sales.xlsx')\n",
    "sales\n",
    "\n",
    "##### Sales and Profit data is read in dataframe \"sales\"\n",
    "\n",
    "# Read file and set 2nd column as index\n",
    "\n",
    "sales = pd.read_excel('sales.xlsx', index_col = [1])\n",
    "sales\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 1 (Column Indexing)</h4>  \n",
    "'''))\n",
    "\n",
    "##### Display Sales Column\n",
    "\n",
    "sales[\"Sales\"]\n",
    "\n",
    "sales.Sales\n",
    "\n",
    "type(sales[\"Sales\"])\n",
    "\n",
    "##### Display Sales and Profit Column together\n",
    "\n",
    "sales[[\"Sales\", \"Profit\"]]\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 2 (Row Indexing)</h4>  \n",
    "'''))\n",
    "\n",
    "##### Display data for \"Southern Asia\"\n",
    "\n",
    "# loc accessor takes row index and column index\n",
    "\n",
    "sales.loc[\"Southern Asia\"]\n",
    "\n",
    "##### Display Sales data for \"Southern Asia\"\n",
    "\n",
    "sales.loc[\"Southern Asia\", \"Sales\"]\n",
    "\n",
    "##### Display data for \"Southern Asia\"\n",
    "\n",
    "# iloc accessor takes row number and column number\n",
    "\n",
    "sales.iloc[6]\n",
    "\n",
    "sales.iloc[6,3]\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 3 (Slicing)</h4>\n",
    "'''))  \n",
    "\n",
    "##### Display data for  Market, Sales and Profit\n",
    "\n",
    "sales.loc[:, [\"Market\", \"Sales\", \"Profit\"]].head()\n",
    "\n",
    "sales.iloc[:, [0,3,2] ].head()\n",
    "\n",
    "##### Display data for Western Africa Southern Africa and North Africa\n",
    "\n",
    "sales.loc[[\"Western Africa\", \"Southern Africa\", \"North Africa\"] ,:]\n",
    "\n",
    "sales.iloc[0:3, :]\n",
    "\n",
    "##### Display Sales and Profit data for Western Africa Southern Africa and North Africa\n",
    "\n",
    "sales.loc[[\"Western Africa\", \"Southern Africa\", \"North Africa\"] , [\"Sales\", \"Profit\"]]\n",
    "\n",
    "sales.iloc[0:3, 2:4]\n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 4 (Filtering)</h4> \n",
    "''')) \n",
    "\n",
    "##### Display Markets with Sales >300000\n",
    "\n",
    "sales[\"Sales\"] > 300000\n",
    "\n",
    "sales[ sales[\"Sales\"] > 300000 ]\n",
    "\n",
    "##### Display the LATAM and Eruopean countries with sales > 250000\n",
    "\n",
    "sales[  (sales[\"Market\"].isin([\"LATAM\", \"Europe\"])) & (sales[\"Sales\"] > 250000)     ]\n",
    "\n",
    "### Optional Examples \n",
    "\n",
    "# The examples given below are good to know but not essential to achieve the objective of this session. You can go through them at your own pace. \n",
    "\n",
    "display(HTML('''\n",
    "<h4 style = \"color : Sky blue\"> Example - 5 (Transformation)</h4>  \n",
    "'''))  \n",
    "\n",
    "# ##### Replace the sales values in the form of thousands\n",
    "\n",
    "# Context: Some time you might want to modify columns to make them more readable. For instance, the sales column in the given data set has six digits, followed by two decimal places. You might want to make it more readable. You can convert the actual sales number to a number in thousands and make it a round figure. \n",
    "\n",
    "# eg. 300000 - 300K\n",
    "\n",
    "# You can use the .floordiv function to achieve the transformation explained above. You can read more about the .floordiv method [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.floordiv.html). \n",
    "\n",
    "sales.Sales = sales.Sales.floordiv(1000)\n",
    "\n",
    "sales.head()\n",
    "\n",
    "sales.rename(columns={'Sales': 'Sales in Thousands'}, inplace=True)\n",
    "sales.head()\n",
    "\n",
    "##### Replace values in Profit percent of total\n",
    "\n",
    "sales.head()\n",
    "\n",
    "#sales['Profit']\n",
    "total_sum = sales.Profit.sum()\n",
    "sales['Profit % of Total'] = sales.Profit.apply(lambda x: x/total_sum*100)\n",
    "\n",
    "sales.head()\n",
    "\n",
    "##### Replace negative Profits with NAN\n",
    "\n",
    "sales.loc[sales['Profit']<0, 'Profit'] = np.nan\n",
    "sales.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Pandas_Udemy'>Pandas_Udemy</a><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "labels = ['a','b','c']\n",
    "my_data = [10,20,30]\n",
    "arr = np.array(my_data)\n",
    "\n",
    "d = dict()\n",
    "for i in range(len(labels)):\n",
    "    d[labels[i]] = my_data[i]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.Series(data = my_data))\n",
    "display(pd.Series(arr, labels))  # i/p: ([10 20 30],['a','b','c'])   ;   o/p: labels,arr\n",
    "display(pd.Series(labels, arr))  # o/p: arr, labels\n",
    "display(pd.Series(d))\n",
    "display(pd.Series(data = labels))\n",
    "display(pd.Series(data = [sum,print,len]))\n",
    "\n",
    "a = pd.Series([1,2,3,4],['-1','-2','-3','-4'])\n",
    "display(a[0],a[1])\n",
    "b = pd.Series([1,2,3,4],['-1','-5','-3','-4'])\n",
    "print(a + b)\n",
    "print(a - b)\n",
    "print(a ** b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas - Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "\n",
    "np.random.seed(1)\n",
    "df = pd.DataFrame(randn(5,4),['A','B','C','D','E'],['W','X','Y','Z'])\n",
    "\n",
    "display(df)\n",
    "display(type(df))\n",
    "display(type(df['W']))  # column selection\n",
    "display((df[0:1]))  #row selection\n",
    "display(type(df[0:1]))\n",
    "\n",
    "df['E'] = 2* df['W']\n",
    "display(df)\n",
    "df.drop(\"Z\",axis=1,inplace=True)  # default -> axis=0 -> row ; axis=1 -> column\n",
    "display(df)\n",
    "display(df.loc['A'])\n",
    "display(df.iloc[1])  # 2nd row\n",
    "\n",
    "display(df.loc['A','Y'])  #row, column\n",
    "#display(df.loc['Y','A'])  #error\n",
    "\n",
    "display(df.loc[['A','A',\"B\"],['Y',\"X\",\"Y\"]]) \n",
    "display(df.iloc[[1,2,2],[1,2,2]]) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas - Dataframes - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df > 0)\n",
    "display(df[df['W']>0][['X','Y']])\n",
    "display(df[df['W']>0][df['X']<=0])\n",
    "display(df[(df['W']>0)&(df['X']<=0)])\n",
    "display(df[(df['W']>0)|(df['X']<=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=False)\n",
    "#df.set_index('index',inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas - Dataframes - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside = ['g1','g1','g1','g2','g2','g2']\n",
    "inside = [1,2,3,1,2,3]\n",
    "hier_index = list(zip(outside,inside))\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(randn(6,2),hier_index,['A','B'])\n",
    "display(df)\n",
    "display(df.loc['g1'])\n",
    "display(df.loc['g1'].loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = ['Groups','Num']\n",
    "display(df)\n",
    "display(df.loc['g2'])\n",
    "display(df.xs('g2'))\n",
    "display(df.xs(1,level=\"Num\"))\n",
    "display(df.xs(2,level=\"Num\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas - Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'A':[1,2,np.nan],\n",
    "    'B':[5,np.nan,np.nan],\n",
    "    'C':[1,2,3]\n",
    "}\n",
    "df = pd.DataFrame(d)  #shift + tab to get info about commands\n",
    "display(df)\n",
    "display(df.dropna())  # row-wise by default (axis=0)\n",
    "#display(df)\n",
    "df.dropna(axis=1)\n",
    "display(df.dropna(thresh=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.fillna('blank'))\n",
    "display(df.fillna(value=df['A'].mean()))\n",
    "display(df.fillna(value=df['A'].median()))\n",
    "display(df.fillna(value=df['A'].mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Company':['google','google','microsoft','microsoft','rakuten','rakuten'],\n",
    "    'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n",
    "    'Sales':[200,120,340,124,243,350]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "byComp = df.groupby('Company') # <pandas.core.groupby.generic.DataFrameGroupBy object at 0x1291184f0>\n",
    "display(byComp.sum())\n",
    "display(byComp.sum().loc['rakuten'])\n",
    "display(df.groupby('Company').min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.groupby('Company').describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Define the IST timezone\n",
    "ist = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "# Get the current time in UTC\n",
    "utc_now = datetime.now(pytz.utc)\n",
    "\n",
    "# Convert the current time to IST\n",
    "ist_now = utc_now.astimezone(ist)\n",
    "\n",
    "# Print the current time in IST\n",
    "print(\"Current Time in IST:\", ist_now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
